{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6632dde5-88fb-4c6c-848d-6dcf8094cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import groq\n",
    "import chromadb\n",
    "import bs4\n",
    "import requests\n",
    "import pdfplumber\n",
    "import sentence_transformers\n",
    "print(\"All libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8b3d9ed-6bdf-4286-b813-6a251ba74407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['qwen/qwen3-32b', 'meta-llama/llama-guard-4-12b', 'playai-tts', 'meta-llama/llama-prompt-guard-2-86m', 'whisper-large-v3-turbo', 'moonshotai/kimi-k2-instruct', 'meta-llama/llama-prompt-guard-2-22m', 'playai-tts-arabic', 'llama-3.1-8b-instant', 'openai/gpt-oss-120b', 'llama-3.3-70b-versatile', 'moonshotai/kimi-k2-instruct-0905', 'meta-llama/llama-4-scout-17b-16e-instruct', 'whisper-large-v3', 'meta-llama/llama-4-maverick-17b-128e-instruct', 'openai/gpt-oss-20b', 'groq/compound-mini', 'allam-2-7b', 'groq/compound']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"  # Replace with your full key\n",
    "\n",
    "# Verify API key with Groq\n",
    "from groq import Groq\n",
    "client = Groq()\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    print(\"Available models:\", [model.id for model in models.data])\n",
    "except Exception as e:\n",
    "    print(f\"API key error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49b877f8-d455-4dff-8e18-54a8574361c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Summary: Here's a 2-sentence summary of the paragraph:\n",
      "\n",
      "Transformers are a type of neural network architecture introduced in 2017 that have significantly impacted the field of Natural Language Processing (NLP). They achieved this by utilizing self-attention mechanisms, a key innovation that has revolutionized the way NLP models process and understand language.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load the Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Define a prompt template for summarization\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following paragraph in 2 sentences: {paragraph}\"\n",
    ")\n",
    "\n",
    "# Chain the prompt with the LLM\n",
    "chain = prompt | llm\n",
    "\n",
    "try:\n",
    "    # Test invocation\n",
    "    response = chain.invoke({\n",
    "        \"paragraph\": \"Transformers are a type of neural network architecture introduced in 2017 that revolutionized NLP by using self-attention mechanisms.\"\n",
    "    })\n",
    "    print(\"Success! Summary:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error during invocation: {str(e)}\")\n",
    "    print(\"Try fallback model: 'gemma-7b-it'. Check https://console.groq.com/docs/models for latest.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4363df6-81ba-4185-9764-6b342566a89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Large Language Models (LLMs) are advanced AI systems trained on large datasets to generate human-like text, and are used in applications such as chatbots, translation, and content creation.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Test summarization\n",
    "summarize_prompt = ChatPromptTemplate.from_template(\"Summarize this paragraph: {text}\")\n",
    "summarize_chain = summarize_prompt | llm\n",
    "\n",
    "text = \"Large Language Models (LLMs) are advanced AI systems trained on massive datasets to generate human-like text. They power applications like chatbots, translation, and content generation.\"\n",
    "response = summarize_chain.invoke({\"text\": text})\n",
    "print(\"Summary:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01aec365-110e-4ded-8b92-c7758f7d0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Web Crawler and PDF Scraper tools\n",
    "from langchain.tools import tool\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfplumber\n",
    "\n",
    "@tool\n",
    "def web_crawler(url: str) -> str:\n",
    "    \"\"\"Fetches plain text content from a webpage URL.\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = ' '.join([p.get_text() for p in soup.find_all(['p', 'h1', 'h2', 'h3'])])\n",
    "        return text.strip()[:2000]\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching URL: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def research_paper_scraper(pdf_path: str) -> str:\n",
    "    \"\"\"Extracts abstract, introduction, and conclusion from a PDF research paper.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \"\"\n",
    "            current_section = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    lines = page_text.split('\\n')\n",
    "                    for line in lines:\n",
    "                        line_lower = line.lower()\n",
    "                        if \"abstract\" in line_lower:\n",
    "                            current_section = \"abstract\"\n",
    "                        elif \"introduction\" in line_lower:\n",
    "                            current_section = \"introduction\"\n",
    "                        elif \"conclusion\" in line_lower:\n",
    "                            current_section = \"conclusion\"\n",
    "                        if current_section:\n",
    "                            text += line + \" \"\n",
    "            return text.strip()[:2000]\n",
    "    except Exception as e:\n",
    "        return f\"Error processing PDF: {str(e)}\"\n",
    "\n",
    "print(\"Tools defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa18b84a-beb0-48d2-a36f-11045d75576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Crawler Output:\n",
      "--------------------------------------------------\n",
      "Contents Transformer (deep learning architecture) In deep learning, the transformer is a neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table.[1] At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \n",
      " Transformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM).[2] Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.[3]\n",
      " \n",
      "The modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google.[1] The predecessors of transformers were developed as an improvement over previous architectures for machine translation,[4][5] but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning,[6][7] audio,[8] multimodal learning, robotics,[9] and even playing chess.[10] It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs)[11] and BERT[12] (bidirectional encoder representations from transformers). History Predecessors For many years, sequence modelling and generation was done by using plain recurrent neural networks (RNNs). A well-cited early example was the Elman network (1990). In theory, the information from one token can propagate arbitrarily far down the sequence, but in practice the vanishing-gradient problem leaves the model's state at the end of a long sentence without precise, extractable information about preced\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Test web crawler\n",
    "url = \"https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\"\n",
    "try:\n",
    "    global web_result\n",
    "    web_result = web_crawler.invoke(url)\n",
    "    print(\"Web Crawler Output:\\n\" + \"-\"*50 + \"\\n\" + web_result + \"\\n\" + \"-\"*50)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"Try alternative URL: https://huggingface.co/blog/transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f113f76-0266-4f2f-9fa3-820728685f7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Scraper Output: Abstract ThisdocumentprovidesanoverviewoftheTransformerarchitecture, acorner- stone of modern artificial intelligence, particularly in natural language processing and computer vision. We explore its s ...\n",
      "Abstract ThisdocumentprovidesanoverviewoftheTransformerarchitecture, acorner- stone of modern artificial intelligence, particularly in natural language processing and computer vision. We explore its structure, key components, applications, and impactonAIadvancements. 1 Introduction The Transformer architecture, introduced in the seminal paper “Attention is All You Need”byVaswanietal. (2017),revolutionizedartificialintelligencebyprovidingahighly efficient and scalable model for sequence-to-sequence tasks. Unlike its predecessors, suchasrecurrentneuralnetworks(RNNs),Transformersrelyentirelyonattentionmech- anisms,enablingfastertrainingandsuperiorperformanceonlargedatasets. 2 Transformer Architecture The Transformer is built on a novel architecture that leverages self-attention mecha- nismstoprocessinputdata. Itskeycomponentsinclude: 2.1 Encoder-DecoderStructure The Transformer consists of stacked encoder and decoder layers. Each encoder pro- cessesinputsequences,whilethedecodergeneratesoutputsequences. Thisstructureis particularlyeffectivefortaskslikemachinetranslation. 2.2 Self-AttentionMechanism ThecoreinnovationofTransformersistheself-attentionmechanism,whichallowsthe model to weigh the importance of different words in a sequence relative to each other. Theattentionmechanismisdefinedas: ( ) QKT Attention(Q,K,V) = softmax √ V d k where Q, K, and V represent query, key, and value vectors, respectively, and d is the k dimensionofthekeys. 2.3 Multi-HeadAttention Multi-headattentionenhancesthemodelbyallowingittofocusondifferentpartsofthe inputsimultaneously,improvingitsabilitytocapturecomplexpatterns. 1 2.4 PositionalEncoding SinceTransformersprocessinputsequencesinparallel(unlikeRNNs),positionalencod- ingsareaddedtoinputembeddingstoretaininformationaboutwordorder. 2.5 Feed-ForwardNetworksandLayerNormalization Eachencoderanddecoderlayerincludesafeed-forwardneuralnetworkandlayernor- malizationtostabilizeandacceleratetraining. 3 Applications of Transformers Transformersha\n"
     ]
    }
   ],
   "source": [
    "# Test PDF scraper\n",
    "pdf_path = \"transformer.pdf\"  # Ensure this file exists in your project folder\n",
    "pdf_result = research_paper_scraper.invoke(pdf_path)\n",
    "print(\"PDF Scraper Output:\", pdf_result[:200], \"...\")\n",
    "print(pdf_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d299056-ed0e-4a89-a384-6cd42b47d8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 577, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully!\n",
      "Result 1 (Metadata: {'source': 'document_1', 'type': 'web'}): Contents Transformer (deep learning architecture) In deep learning, the transformer is a neural netw...\n",
      "Result 2 (Metadata: {'source': 'document_1', 'type': 'web'}): The modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by ...\n",
      "Result 3 (Metadata: {'source': 'document_2', 'type': 'pdf'}): Abstract ThisdocumentprovidesanoverviewoftheTransformerarchitecture, acorner- stone of modern artifi...\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import shutil\n",
    "\n",
    "# Clear existing vector store to avoid duplicates\n",
    "shutil.rmtree(r\"C:\\Users\\punithb\\capstone project 2.0\\chroma_db1\", ignore_errors=True)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create documents (assuming web_result and pdf_result are defined)\n",
    "documents = []\n",
    "if \"Error\" not in web_result:\n",
    "    documents.append(web_result)\n",
    "if \"Error\" not in pdf_result:\n",
    "    documents.append(pdf_result)\n",
    "\n",
    "# Split documents into chunks and assign metadata\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50, separator=\"\\n\")\n",
    "chunks = []\n",
    "metadatas = []\n",
    "for i, doc in enumerate(documents):\n",
    "    doc_chunks = text_splitter.split_text(doc)\n",
    "    chunks.extend(doc_chunks)\n",
    "    metadatas.extend([{\"source\": f\"document_{i+1}\", \"type\": \"web\" if i == 0 else \"pdf\"}] * len(doc_chunks))\n",
    "\n",
    "# Create vector store\n",
    "try:\n",
    "    vectorstore = Chroma.from_texts(\n",
    "        texts=chunks,\n",
    "        embedding=embeddings,\n",
    "        collection_name=\"rag_collection\",\n",
    "        persist_directory=r\"C:\\uses\\punithb\\capstone project 2.0\\chroma_db1\",\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    print(\"Vector store created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating vector store: {str(e)}\")\n",
    "\n",
    "# Perform similarity search\n",
    "try:\n",
    "    results = vectorstore.similarity_search(\"What is a transformer in NLP?\", k=3)\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i+1} (Metadata: {result.metadata}): {result.page_content[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Search error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7caa115a-48ee-4413-8c79-d9ebce5e51ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 577, which is longer than the specified 200\n",
      "Created a chunk of size 311, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer:\n",
      "--------------------------------------------------\n",
      "Unfortunately, the provided context does not mention singing. It appears to be about the transformer architecture in deep learning, its applications, and its advantages over previous architectures. Therefore, I cannot provide a relevant answer to the question about singing.\n",
      "--------------------------------------------------\n",
      "Sources:\n",
      "--------------------------------------------------\n",
      "Source 1 (Metadata: {'source': 'document_1', 'type': 'web'}):\n",
      "Contents Transformer (deep learning architecture) In deep learning, the transformer is a neural netw...\n",
      "\n",
      "Source 2 (Metadata: {'source': 'document_1', 'type': 'web'}):\n",
      "The modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by ...\n",
      "\n",
      "Source 3 (Metadata: {'source': 'document_1', 'type': 'web'}):\n",
      "Transformers have the advantage of having no recurrent units, therefore requiring less training time...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import shutil\n",
    "\n",
    "# Function to add space after each letter in a string (for PDF chunks)\n",
    "def add_space_after_letters(text):\n",
    "    return \"\".join(c + \" \" if c.isalnum() else c for c in text)\n",
    "\n",
    "# Clear existing vector store\n",
    "shutil.rmtree(r\"C:\\Users\\punithb\\capstone project 2.0\\chroma_db1\", ignore_errors=True)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create documents (assuming web_result and pdf_result are defined)\n",
    "documents = []\n",
    "if \"Error\" not in web_result:\n",
    "    documents.append(web_result)\n",
    "if \"Error\" not in pdf_result:\n",
    "    documents.append(pdf_result)\n",
    "\n",
    "# Split documents into chunks and assign metadata\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20, separator=\"\\n\")\n",
    "chunks = []\n",
    "metadatas = []\n",
    "for i, doc in enumerate(documents):\n",
    "    doc_chunks = text_splitter.split_text(doc)\n",
    "    chunks.extend(doc_chunks)\n",
    "    metadatas.extend([{\"source\": f\"document_{i+1}\", \"type\": \"web\" if i == 0 else \"pdf\"}] * len(doc_chunks))\n",
    "\n",
    "# Create and persist vector store\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"rag_collection\",\n",
    "    persist_directory=r\"C:\\Users\\punithb\\capstone project 2.0\\chroma_db1\",\n",
    "    metadatas=metadatas\n",
    ")\n",
    "\n",
    "# Load vector store\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"rag_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=r\"C:\\Users\\punithb\\capstone project 2.0\\chroma_db1\"\n",
    ")\n",
    "\n",
    "# Set up retriever with MMR\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# Format documents with metadata, adding spaces for PDF chunks\n",
    "def format_docs(docs):\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        if not isinstance(doc.page_content, str):\n",
    "            continue\n",
    "        content = doc.page_content\n",
    "        if doc.metadata.get(\"type\") == \"pdf\":\n",
    "            content = add_space_after_letters(content)\n",
    "        formatted_docs.append(f\"Source: {doc.metadata.get('source', 'unknown')} ({doc.metadata.get('type', 'unknown')})\\nContent: {content}\")\n",
    "    return \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "# RAG prompt\n",
    "rag_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Use the following context to answer the question: \\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "# Create RAG chain (assuming llm is defined)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Test RAG pipeline\n",
    "query = \"What is singing?\"\n",
    "response = rag_chain.invoke(query)\n",
    "print(\"RAG Answer:\\n\" + \"-\"*50 + \"\\n\" + response + \"\\n\" + \"-\"*50)\n",
    "sources = retriever.invoke(query)\n",
    "print(\"Sources:\\n\" + \"-\"*50)\n",
    "for i, doc in enumerate(sources):\n",
    "    print(f\"Source {i+1} (Metadata: {doc.metadata}):\\n{doc.page_content[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d91fe6-6d8d-49d1-8aef-fe356dc2346e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
